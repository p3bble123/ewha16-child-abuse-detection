# -*- coding: utf-8 -*-
"""final_detect.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1b-EqVRiespKVjejrwgfo6U-GUsmHU_79

# **Openpose 1.7.0 Demo Build**
"""

from google.colab import drive
drive.mount('/content/drive')

# Confirm runtime to GPU
! nvcc --version
! nvidia-smi

# Openpose version tag
ver_openpose = "v1.7.0"
! echo $ver_openpose

# If CMake is old, Openpose build fails, so download the latest version
# https://developercommunity.visualstudio.com/content/problem/354325/cmake-project-cannot-detect-cuda-10.html
! cmake --version

# Rebuild the latest CMake as of 2021.03.03 (about 15 minutes)
! wget -c "https://github.com/Kitware/CMake/releases/download/v3.19.6/cmake-3.19.6.tar.gz"
! tar xf cmake-3.19.6.tar.gz
! cd cmake-3.19.6 && ./configure && make && sudo make install

# Install library
# Basic
! sudo apt-get --assume-yes update
! sudo apt-get --assume-yes install build-essential
# OpenCV
! sudo apt-get --assume-yes install libopencv-dev
# General dependencies
! sudo apt-get --assume-yes install libatlas-base-dev libprotobuf-dev libleveldb-dev libsnappy-dev libhdf5-serial-dev protobuf-compiler
! sudo apt-get --assume-yes install --no-install-recommends libboost-all-dev
# Remaining dependencies, 14.04
! sudo apt-get --assume-yes install libgflags-dev libgoogle-glog-dev liblmdb-dev
# Python3 libs
! sudo apt-get --assume-yes install python3-setuptools python3-dev build-essential
! sudo apt-get --assume-yes install python3-pip
! sudo -H pip3 install --upgrade numpy protobuf opencv-python
# OpenCL Generic
! sudo apt-get --assume-yes install opencl-headers ocl-icd-opencl-dev
! sudo apt-get --assume-yes install libviennacl-dev

# Clone Openpose
! git clone  --depth 1 -b "$ver_openpose" https://github.com/CMU-Perceptual-Computing-Lab/openpose.git

# Create build directory
! cd openpose && mkdir build && cd build

# https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/doc/installation.md#cmake-command-line-configuration-ubuntu-only
# Scenario 1 - Caffe not installed and OpenCV installed using apt-get
! cd openpose/build && cmake ..

# Openpose Building
! cd openpose/build && make -j`nproc`

"""# **KEYPOINTS JSON 파일 추출 시작**"""

import os
import json
from glob import glob
import numpy as np
import pandas as pd

# 폴더 생성
def createFolder(directory):
  try:
      if not os.path.exists(directory):
          os.makedirs(directory)
  except OSError:
      print ('Error: Creating directory. ' +  directory)

createFolder('/content/drive/MyDrive/TEST_JSON') 
createFolder('/content/drive/MyDrive/TEST_NUMPY')

# 폭력행위 동영상 json 추출

address = '/content/drive/MyDrive/test.mp4'
root_path = "/content/drive/MyDrive"
dest = '/content/drive/MyDrive/TEST_JSON'

! cd '/content/openpose' && ./build/examples/openpose/openpose.bin --video "$address" --write_json "$dest" --display 0 --write_video "$root_path/test.avi" --number_people_max 2

# Commented out IPython magic to ensure Python compatibility.
# json >> numpy 변환 

path = '/content/drive/MyDrive/TEST_JSON'
# % cd '$path'
for filename in sorted(glob('*.json')):
  with open(filename) as json_file:
      json_data = json.load(json_file)
      a = json_data['people']

      if len(a) == 2:
          s1=np.array(a[0]['pose_keypoints_2d'])
          ss1 = s1[:57]
          s2=np.array(a[1]['pose_keypoints_2d'])
          ss2 = s2[:57]
          ss = np.concatenate((ss1, ss2), axis=0)
          fin= ss.reshape(2,19,3)
          name = filename[:-5]
          np.save('/content/drive/MyDrive/TEST_NUMPY/'+name, fin)

      elif len(a) ==1:
          s1=np.array(a[0]['pose_keypoints_2d'])
          ss1 = s1[:57]
          z = np.zeros((57,))
          ss = np.concatenate((ss1, z), axis=0)
          fin = ss.reshape(2,19,3)
          name = filename[:-5]
          np.save('/content/drive/MyDrive/TEST_NUMPY/'+name, fin)

      elif len(a) ==0 :
          print("no data")

"""# **frame별 KEYPOINTS Processing 시작**"""

# 어른 아이 구분 함수

def separate_adult(current_keypoints, confidence_threshold):
  i = 0
  adult_index = 0
  max_height = 0
  height=0

  for person in current_keypoints:
      n = 0
      b1,b2,b3,b4 = 0,0,0,0

      if(person[2][2] >= confidence_threshold) and (person[3][2] >= confidence_threshold) :
        b1 = (((person[2][0]-person[3][0])**2)+((person[2][1]-person[3][1])**2))**0.5 
        n+=1
      else:
        b1=0

      if (person[5][2] >= confidence_threshold) and (person[6][2] >= confidence_threshold) :
        b2 = (((person[5][0]-person[6][0])**2)+((person[5][1]-person[6][1])**2))**0.5 
        n+=1
      else:
        b2=0

      if (person[9][2] >= confidence_threshold) and (person[10][2] >= confidence_threshold) :
        b3 =  (((person[9][0]-person[10][0])**2)+((person[9][1]-person[10][1])**2))**0.5
        n+=1
      else:
        b3=0

      if (person[12][2] >= confidence_threshold) and (person[13][2] >= confidence_threshold) :
        b4 = (((person[12][0]-person[13][0])**2)+((person[12][1]-person[13][1])**2))**0.5
        n+=1
      else:
        b4 = 0
       
      if n != 0:
        height = (b1+b2+b3+b4)/n
      else:
        height=0 

      if height >= max_height:
        max_height = height
        adult_index = i

      i += 1

  return adult_index

# keypoint별 벡터 크기(속력) 구하기
def keypoint_vector(previous_keypoints, current_keypoints, confidence_threshold):

  p_adult_keypoints = previous_keypoints[separate_adult(previous_keypoints, 0.1)]
  c_adult_keypoints = current_keypoints[separate_adult(current_keypoints, 0.1)]

  # 벡터 차이 구하기
  vector = np.zeros((19,2)) 
  for i in range(19):
    # confidence 역치 이상일 때만
    if (p_adult_keypoints[i][2] >= confidence_threshold) and (c_adult_keypoints[i][2] >= confidence_threshold):
      vector[i][0] = c_adult_keypoints[i][0] - p_adult_keypoints[i][0]
      vector[i][1] = c_adult_keypoints[i][1] - p_adult_keypoints[i][1]
    else:
      vector[i] = [0,0]

  return vector

def sub(x1,x2):
  return x1[0] - x2[0],x1[1] - x2[1]

import math

def dist(x1,x2) -> int:
  x = x1[0]-x2[0]
  y = x1[1]-x2[1]
  return math.sqrt(x**2 + y**2)

def relationKeypoint(current_keypoints, confidence_threshold, distanceArray):

  adult_keypoints = current_keypoints[separate_adult(current_keypoints, 0.1)]

  # 벡터 차이 구하기
  vector = np.zeros((22,1)) 

  #f4
  d4 = distanceArray[0] + distanceArray[2] + distanceArray[3] + distanceArray[5] +distanceArray[7]  
  if d4 != 0:
    vector[0],vector[1] = sub(adult_keypoints[0],adult_keypoints[1])/d4  # head - neck 
    vector[2],vector[3] = sub(adult_keypoints[4],adult_keypoints[1])/d4  # right hand - neck 
    vector[4],vector[5] = sub(adult_keypoints[7],adult_keypoints[1])/d4  # left hand - neck 
  else:
    vector[0],vector[1],vector[2],vector[3],vector[4],vector[5] = None,None,None,None,None,None
 
  #f5
  d5 = distanceArray[2] + distanceArray[3] + distanceArray[9] + distanceArray[11] 
  if d5 != 0:
    vector[6],vector[7] = sub(adult_keypoints[1],adult_keypoints[12])/d5     # neck - left hip 
    vector[8],vector[9] = sub(adult_keypoints[4],adult_keypoints[12])/d5     # right hand - left hip 
    vector[10],vector[11] = sub(adult_keypoints[11],adult_keypoints[12])/d5  # right foot - left hip
  else:
    vector[6],vector[7],vector[8],vector[9],vector[10],vector[11]= None,None,None,None,None,None
 
  #f6
  d6 = distanceArray[5] + distanceArray[6] + distanceArray[10] + distanceArray[12] 
  if d6 != 0:
    vector[12],vector[13] = sub(adult_keypoints[0],adult_keypoints[9])/d6   # head - right hip 
    vector[14],vector[15] = sub(adult_keypoints[7],adult_keypoints[9])/d6   # left hand - right hip 
    vector[16],vector[17] = sub(adult_keypoints[14],adult_keypoints[9])/d6  # left foot - right hip 
  else:
    vector[12],vector[13],vector[14],vector[15],vector[16],vector[17]= None,None,None,None,None,None
  
  #f7
  d7 = distanceArray[2] + distanceArray[3] + distanceArray[5] + distanceArray[6] 
  if d7 != 0:
    vector[18],vector[19] = sub(adult_keypoints[4],adult_keypoints[0])/d7  # right hand - head 
    vector[20],vector[21] = sub(adult_keypoints[7],adult_keypoints[0])/d7  # left hand - head 
  else:
    vector[18],vector[19],vector[20],vector[21]= None,None,None,None

  return vector

def distanceVector(norm_vector):
  distanceArray = np.zeros((13,1))
  
  distanceArray[0] = dist((norm_vector[0],norm_vector[1]),(norm_vector[2],norm_vector[3])) #머리-목
  distanceArray[1] = dist((norm_vector[2],norm_vector[3]),(norm_vector[4],norm_vector[5])) #목-오른어깨
  distanceArray[2] = dist((norm_vector[4],norm_vector[5]),(norm_vector[6],norm_vector[7])) #오른어깨-오른엘보우
  distanceArray[3] = dist((norm_vector[6],norm_vector[7]),(norm_vector[8],norm_vector[9])) #오른엘보우-오른손목
  distanceArray[4] = dist((norm_vector[2],norm_vector[3]),(norm_vector[10],norm_vector[11])) #목-왼어깨
  distanceArray[5] = dist((norm_vector[10],norm_vector[11]),(norm_vector[12],norm_vector[13])) #왼어꺠-왼엘보우
  distanceArray[6] = dist((norm_vector[12],norm_vector[13]),(norm_vector[14],norm_vector[15])) #왼엘보우-왼손목
  distanceArray[7] = dist((norm_vector[2],norm_vector[3]),(norm_vector[18],norm_vector[19])) #목-오른힙
  distanceArray[8] = dist((norm_vector[2],norm_vector[3]),(norm_vector[24],norm_vector[25])) #목-왼힙
  distanceArray[9] = dist((norm_vector[18],norm_vector[19]),(norm_vector[20],norm_vector[21])) #오른힙-오른무릎
  distanceArray[10] = dist((norm_vector[24],norm_vector[25]),(norm_vector[26],norm_vector[27])) #왼힙-왼무릎
  distanceArray[11] = dist((norm_vector[20],norm_vector[21]),(norm_vector[22],norm_vector[23])) #오른무릎-오른발목
  distanceArray[12] = dist((norm_vector[26],norm_vector[27]),(norm_vector[28],norm_vector[29])) #왼무릎-왼발목

  return distanceArray

def normalize(previous_keypoints, current_keypoints, confidence_threshold) :
  
  norm_vector = np.zeros((30,1)) # 30개
  distanceArray = np.zeros((13,1)) # D1~D13
  relationVector = np.zeros((22,1))
  final_vector = np.zeros((52,1)) # 30+22

  vector = keypoint_vector(previous_keypoints, current_keypoints, 0.1)
  
  #head
  norm_vector[0],norm_vector[1] = (vector[15][0]+vector[16][0])//2,(vector[15][1]+vector[16][1])//2
  #neck
  norm_vector[2],norm_vector[3] = vector[1][0],vector[1][1]

  #norm_vector로 옮기기 (4+(13*2)=30개)
  for i,points in enumerate(vector):
    if i>=2 and i<=14:
      x_idx,y_idx = ((i-2)*2)+4,((i-2)*2)+5
      norm_vector[x_idx] = points[0]
      norm_vector[y_idx] = points[1]
  
  # 신체 거리 구하기
  distanceArray = distanceVector(norm_vector) # D1~D13


  #변위 벡터 계산
  #f1
  d1 = distanceArray[0] + distanceArray[3] + distanceArray[6] + distanceArray[11] +distanceArray[12]   # D1+D4+D7+D12+D13
  if d1 != 0:
    norm_vector[0],norm_vector[1] = norm_vector[0]/d1,norm_vector[1]/d1         #head
    norm_vector[14],norm_vector[15] = norm_vector[14]/d1,norm_vector[15]/d1     #left hand
    norm_vector[8],norm_vector[9] = norm_vector[8]/d1,norm_vector[9]/d1         #right hand 
    norm_vector[28],norm_vector[29] = norm_vector[28]/d1,norm_vector[29]/d1     #left foot
    norm_vector[22],norm_vector[23] = norm_vector[22]/d1,norm_vector[23]/d1     #right foot
  else:
    norm_vector[0],norm_vector[1],norm_vector[14],norm_vector[15],norm_vector[8],norm_vector[9],norm_vector[28],norm_vector[29],norm_vector[22],norm_vector[23]=None,None,None,None,None,None,None,None,None,None

  #f2
  d2 = distanceArray[0] + distanceArray[2] + distanceArray[5] + distanceArray[9] +distanceArray[10]
  if d2 != 0:
    norm_vector[2],norm_vector[3] = norm_vector[2]/d2,norm_vector[3]/d2         #neck
    norm_vector[12],norm_vector[13] = norm_vector[12]/d2,norm_vector[13]/d2     #left elbow
    norm_vector[6],norm_vector[9] = norm_vector[6]/d2,norm_vector[9]/d2         #right elbow
    norm_vector[26],norm_vector[27] = norm_vector[26]/d2,norm_vector[27]/d2     #left knee
    norm_vector[20],norm_vector[21] = norm_vector[20]/d2,norm_vector[21]/d2     #right knee
  else:
    norm_vector[2],norm_vector[3],norm_vector[12],norm_vector[13],norm_vector[6],norm_vector[9],norm_vector[26],norm_vector[27],norm_vector[20],norm_vector[21]= None,None,None,None,None,None,None,None,None,None

  #f3
  d3 = distanceArray[1] + distanceArray[4] + distanceArray[9] + distanceArray[10] 
  if d3 != 0:
    norm_vector[10],norm_vector[11] = norm_vector[10]/d3,norm_vector[11]/d3     #left shoulder
    norm_vector[4],norm_vector[5] = norm_vector[4]/d3,norm_vector[5]/d3         #right shoulder
    norm_vector[24],norm_vector[25] = norm_vector[24]/d3,norm_vector[25]/d3     #left hip
    norm_vector[18],norm_vector[19] = norm_vector[18]/d3,norm_vector[19]/d3     #right hip
    norm_vector[16],norm_vector[17] = norm_vector[16]/d3,norm_vector[17]/d3     #middle hip
  else:
    norm_vector[10],norm_vector[11],norm_vector[4],norm_vector[5],norm_vector[24],norm_vector[25],norm_vector[18],norm_vector[19],norm_vector[16],norm_vector[17] = None,None,None,None,None,None,None,None,None,None
  
  relationVector = relationKeypoint(current_keypoints,confidence_threshold,distanceArray)

  final_vector = np.concatenate((norm_vector, relationVector), axis=0)
  return final_vector

# Commented out IPython magic to ensure Python compatibility.
current_keypoints = None
previous_keypoints = None
input = np.zeros((52,1))

path = '/content/drive/MyDrive/TEST_NUMPY'
# % cd '$path'
filst = sorted(glob('*.npy'))
for fname in filst:
  if previous_keypoints is None:  
    previous_keypoints = np.load(fname)
  else:
    current_keypoints = np.load(fname)
    vector = normalize(previous_keypoints, current_keypoints, 0.1)
    input = np.append(input, vector , axis = 1)
    previous_keypoints = current_keypoints

result = np.delete(input,0,axis=1)
df = pd.DataFrame(result)

"""## **TEST MODEL 시작**"""

!pip install tensorflow==2.4.1 tensorflow-gpu==2.4.1 tensorflow-hub opencv-python matplotlib

df_cut = df[:52]
df_t = np.transpose(df_cut)
df_t['video_num'] = 1
df_t['frame'] = [i for i in range(1,df_t.shape[0]+1)]
df_t.dropna(axis=0, how='any', inplace=True)

df_t.head()

from sklearn.preprocessing import RobustScaler

scale_columns = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,
                 26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51]

scaler = RobustScaler()

scaler = scaler.fit(df_t[scale_columns])

df_t.loc[:, scale_columns] = scaler.transform(
  df_t[scale_columns].to_numpy()
)

def create_dataset(X, time_steps=1, step=1):
    Xs = []
    for i in range(0, len(X) - time_steps, step):
        v = X.iloc[i:(i + time_steps)].values
        Xs.append(v)
    return np.array(Xs)

from scipy import stats
TIME_STEPS = 50
STEP =50 #window 부분 - 파라미터 조정하면서 봐야할듯....

X = create_dataset(
    df_t[[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,
                 26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51]],
    TIME_STEPS,
    STEP
)

print(X.shape)

import tensorflow as tf
model = tf.keras.models.load_model('/content/drive/MyDrive/final_model.h5')
ans = model.predict(X)

def final(ans):
  abuse = np.mean(ans[0])
  normal = np.mean(ans[1])

  if abuse > normal :
    return True

  else :
    return False

print(final(ans))